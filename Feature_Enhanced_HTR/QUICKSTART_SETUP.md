"""
Quick Start Guide for Feature Enhanced HTR

Get the Handwritten Text Recognition system up and running in minutes.
"""

# Feature Enhanced HTR - Quick Start Guide

## ğŸ“¦ What's Been Set Up

âœ… **Dependencies Installed**

- TensorFlow 2.15.1
- OpenCV 4.11.0
- NumPy, Pillow, and other essential libraries

âœ… **Sample Dataset Created**

- 100 synthetic handwritten text images (128Ã—128 pixels)
- 80 training samples
- 20 test samples
- Ground truth labels in JSON format

âœ… **All Components Verified**

- Image Preprocessing module
- CNN Feature Extractor
- BiLSTM Sequence Model
- HRNN Enhancement layer
- CTC Decoder
- NLP Post-processing

## ğŸš€ Quick Start

### 1. Verify Everything is Working

```bash
# Run the component tests
python test_components.py

# Run the demo pipeline
python demo_inference.py
```

### 2. Generate More Sample Data (if needed)

```bash
python generate_sample_dataset.py
```

This creates:

- More synthetic images in `dataset/raw_images/`
- Updated labels in `dataset/labels/`

### 3. Train the Model

```bash
# Using the training script
python train.py --config config.json --epochs 50
```

### 4. Run Inference

```bash
# Using the main inference pipeline
python main.py --image path/to/image.png --model checkpoints/model.h5
```

## ğŸ“ Project Structure

```
Feature_Enhanced_HTR/
â”œâ”€â”€ dataset/                          # Generated dataset
â”‚   â”œâ”€â”€ raw_images/                   # Synthetic images (100 images)
â”‚   â”œâ”€â”€ enhanced_images/              # Preprocessed images
â”‚   â””â”€â”€ labels/                       # Ground truth labels
â”‚
â”œâ”€â”€ model/                            # Model components
â”‚   â”œâ”€â”€ cnn_feature_extractor.py     # Visual feature extraction
â”‚   â”œâ”€â”€ sequence_model.py            # Temporal modeling (BiLSTM)
â”‚   â”œâ”€â”€ enhancement_hrnn.py          # Feature enhancement
â”‚   â””â”€â”€ decoder_ctc.py               # CTC loss & decoding
â”‚
â”œâ”€â”€ preprocessing/
â”‚   â””â”€â”€ preprocess.py                # Image preprocessing
â”‚
â”œâ”€â”€ nlp/
â”‚   â””â”€â”€ postprocess.py               # Text correction & normalization
â”‚
â”œâ”€â”€ test_components.py               # Component verification
â”œâ”€â”€ demo_inference.py                # Demo pipeline
â”œâ”€â”€ generate_sample_dataset.py       # Dataset generation
â”œâ”€â”€ train.py                         # Training pipeline
â”œâ”€â”€ main.py                          # Inference pipeline
â”œâ”€â”€ utils.py                         # Utilities
â””â”€â”€ config.json                      # Configuration
```

## ğŸ”§ Key Components

### Image Preprocessing

- Grayscale conversion
- Gaussian blur (noise reduction)
- Otsu's binary thresholding
- Morphological operations

### CNN Feature Extractor

```
Input (128Ã—128Ã—1)
  â†“
Conv2D(32) â†’ BatchNorm â†’ MaxPool â†’ Dropout
  â†“
Conv2D(64) â†’ BatchNorm â†’ MaxPool â†’ Dropout
  â†“
Conv2D(128) â†’ BatchNorm â†’ MaxPool â†’ Dropout
  â†“
Features (16Ã—16Ã—128)
```

### BiLSTM Sequence Model

- Bidirectional LSTM layers
- Feature extraction from CNN output
- Sequence modeling for variable length text

### HRNN Enhancement

- Multi-head self-attention (4 heads)
- Residual connections
- Layer normalization
- Feed-forward networks

### CTC Decoder

- Alignment-free training
- Greedy and beam search decoding
- Variable length sequence support

### NLP Post-Processing

- Text normalization
- Spell correction (SymSpell)
- Case standardization

## ğŸ“Š Dataset Information

**Generated Dataset Statistics:**

- Total samples: 100
- Train/Test split: 80/20
- Image size: 128Ã—128 pixels
- Image format: PNG, Grayscale
- Text labels: English phrases (2-5 words)
- Average text length: 2.9 words

## ğŸ§ª Sample Results

The demo pipeline processes sample images and shows:

1. **Ground Truth**: Original text from dataset
2. **Predicted**: Recognized text (currently mock predictions)
3. **Normalized**: Post-processed text output

Results are saved to `demo_results.json` for analysis.

## âš™ï¸ Configuration

Edit `config.json` to customize:

```json
{
  "batch_size": 32,
  "epochs": 100,
  "learning_rate": 0.001,
  "input_shape": [128, 128, 1],
  "num_classes": 80,
  "lstm_units": 128,
  "num_lstm_layers": 2
}
```

## ğŸ¯ Training Tips

1. **Start with more data**: Generate larger dataset for better results
2. **Adjust batch size**: Based on GPU memory
3. **Monitor validation**: Early stopping patience is set to 10 epochs
4. **Learning rate**: Default is 0.001, adjust if loss doesn't decrease

## ğŸ› Troubleshooting

**Issue: ModuleNotFoundError**

```bash
# Reinstall dependencies
pip install -r requirements.txt
```

**Issue: Dataset not found**

```bash
# Generate sample dataset
python generate_sample_dataset.py
```

**Issue: Out of memory during training**

```bash
# Reduce batch size in config.json
"batch_size": 16  # Decrease from 32
```

## ğŸ“š Additional Resources

- [API Reference](API_REFERENCE.md) - Detailed API documentation
- [Implementation Summary](IMPLEMENTATION_SUMMARY.md) - Technical details
- [Getting Started](GETTING_STARTED.md) - Detailed setup guide
- [README](README.md) - Full project documentation

## âœ¨ Key Features

âœ… **Production-Ready**: Proper error handling and logging
âœ… **Modular Design**: Each component can be used independently
âœ… **Flexible**: Easy to customize architecture and parameters
âœ… **Well-Documented**: Comprehensive docstrings and examples
âœ… **Tested**: Component validation suite included

## ğŸ“ Learning Path

1. **Understand the dataset** â†’ Run `demo_inference.py`
2. **Verify components** â†’ Run `test_components.py`
3. **Train a model** â†’ Run `train.py`
4. **Run inference** â†’ Use `main.py`
5. **Analyze results** â†’ Check logs and output files

## ğŸš€ Next Steps

1. **Collect real handwritten text data**: For production use
2. **Fine-tune architecture**: Adjust layer sizes and parameters
3. **Implement data augmentation**: Rotation, scaling, skewing
4. **Add more languages**: Extend character set for multi-language support
5. **Deploy to production**: Use TensorFlow Serving or ONNX

## ğŸ“ Support

For issues or questions:

1. Check error logs in `logs/` directory
2. Review component test results in console output
3. Consult the comprehensive API documentation

---

**Status**: âœ… All systems ready for training and inference!

Generated on: 2026-02-03
